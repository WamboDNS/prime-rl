# No difficulty filtering - all rollouts kept
trainer_gpu_ids = [0]
inference_gpu_ids = [1]

max_steps = 50
seq_len = 2048

[wandb]
project = "injection-detector"
name = "injection-detector-no-filtering"

[model]
name = "Qwen/Qwen3-4B-Instruct-2507"

[orchestrator]
batch_size = 32
rollouts_per_example = 16

[orchestrator.sampling]
max_tokens = 4096

[[orchestrator.env]]
id = "wambosec/injection-detector"
name = "injection-detector"
args = { dataset_name = "wambosec/prompt-injections-subtle" }

[trainer.model.lora]
rank = 16
alpha = 32

[inference]
